{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, random\n",
    "import pandas as pd \n",
    "from src.config import Config\n",
    "from src.insights import get_training_dfs\n",
    "from src.utils import display_all\n",
    "import wandb\n",
    "from pandas.io.json._normalize import nested_to_record    \n",
    "\n",
    "seed = 100\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters: (dataset_name, run_name)\n",
    "\n",
    "Csv path: f\"{self._cfg.path_run}{split}.csv\"\n",
    "Initial values are stored at \n",
    "\n",
    "\n",
    "Get names of all runs that differ only in seed \n",
    "    * kind of like: take run_results table, filter to only date you are interested in, group by (everything else than seed) and then concat the run_name to get a list. Then save the list. Now you can enumerate on it. \n",
    "\n",
    "create csv bootstrap_results_{datetime}.csv\n",
    "for run_list in run_lists\n",
    "    Init empty list of tables\n",
    "    For run in run_list: \n",
    "        load + process test table \n",
    "        concat to list \n",
    "    concat all list of tables to make one big table \n",
    "    run bootstrap test on big table \n",
    "    save p-value with run names and common config to bootstrap_results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs(\"uts_nlp/travis_attack\", filters={\"tags\": {\"$in\": [\"final\"]}})\n",
    "summary_params = ['baseline_test', 'any_adv_example_proportion-test',  'is_adv_example-mean-test', 'n_pp-test']\n",
    "config_params = ['decode_method_eval', 'dataset_name', 'seed', 'gen_params_train']\n",
    "\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs: \n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files \n",
    "    d = run.summary._json_dict\n",
    "    d1 = nested_to_record({ k: d[k] for k in summary_params })\n",
    "    l = list(d1.keys())\n",
    "    for k in l: \n",
    "        if 'baseline_test' in k: \n",
    "            if k not in ['baseline_test.any_adv_example_proportion', 'baseline_test.is_adv_example-mean']: d1.pop(k)\n",
    "    summary_list.append(d1)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    d1 = nested_to_record({k: v for k,v in run.config.items() if k in config_params})\n",
    "    for k in ['gen_params_train.top_p','gen_params_train.do_sample']: d1.pop(k)\n",
    "    #d2 = {k: v for k,v in run.config.items() if k in config_params}\n",
    "    config_list.append(d1)\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame({\n",
    "   \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })\n",
    "\n",
    "res_df = pd.concat(objs=[runs_df['name'], pd.DataFrame.from_records(runs_df[\"config\"]), pd.DataFrame.from_records(runs_df[\"summary\"])], axis=1)\n",
    "res_df['avg_num_successes'] = res_df['is_adv_example-mean-test'] * res_df['n_pp-test']\n",
    "res_df['decode_method_eval']  = pd.Categorical(res_df['decode_method_eval'], \n",
    "                      categories=[\"sample\",\"beam_search\",\"diverse_beam_search_low_diversity\",\"diverse_beam_search_high_diversity\"], ordered=False)\n",
    "res_df['dataset_name']  = pd.Categorical(res_df['dataset_name'], \n",
    "                      categories=[\"rotten_tomatoes\",\"financial\"], ordered=False)\n",
    "\n",
    "res_df = res_df.sort_values(['dataset_name', 'decode_method_eval', 'gen_params_train.temperature'])\n",
    "#res_df\n",
    "def replace_names(df): \n",
    "    df['dataset_name'].replace({\"rotten_tomatoes\": \"RT\", \"financial\":\"FP\" }, inplace=True)\n",
    "    df['decode_method_eval'].replace({\"sample\": \"Sample\", \"beam_search\":\"Beam search\",\n",
    "                                         \"diverse_beam_search_low_diversity\": \"Diverse beam search (6 beam groups)\",\n",
    "                                         \"diverse_beam_search_high_diversity\": \"Diverse beam search (48 beam groups)\"}, inplace=True)\n",
    "    df['decode_method_eval']  = pd.Categorical(df['decode_method_eval'], \n",
    "                        categories=[\"Sample\",\"Beam search\",\"Diverse beam search (6 beam groups)\",\"Diverse beam search (48 beam groups)\"], ordered=False)\n",
    "    df['dataset_name']  = pd.Categorical(df['dataset_name'], \n",
    "                        categories=[\"RT\",\"FP\"], ordered=False)\n",
    "    return df \n",
    "res_df = replace_names(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seed</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>decode_method_eval</th>\n",
       "      <th>gen_params_train.temperature</th>\n",
       "      <th>any_adv_example_proportion-test</th>\n",
       "      <th>is_adv_example-mean-test</th>\n",
       "      <th>n_pp-test</th>\n",
       "      <th>baseline_test.any_adv_example_proportion</th>\n",
       "      <th>baseline_test.is_adv_example-mean</th>\n",
       "      <th>avg_num_successes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>proud-sweep-3</td>\n",
       "      <td>1002</td>\n",
       "      <td>RT</td>\n",
       "      <td>Sample</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.339833</td>\n",
       "      <td>0.056066</td>\n",
       "      <td>30.395543</td>\n",
       "      <td>0.306407</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>1.704161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  seed dataset_name decode_method_eval  \\\n",
       "45  proud-sweep-3  1002           RT             Sample   \n",
       "\n",
       "    gen_params_train.temperature  any_adv_example_proportion-test  \\\n",
       "45                          0.85                         0.339833   \n",
       "\n",
       "    is_adv_example-mean-test  n_pp-test  \\\n",
       "45                  0.056066  30.395543   \n",
       "\n",
       "    baseline_test.any_adv_example_proportion  \\\n",
       "45                                  0.306407   \n",
       "\n",
       "    baseline_test.is_adv_example-mean  avg_num_successes  \n",
       "45                           0.024213           1.704161  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run lists \n",
    "cfg = Config()\n",
    "#df_runs = pd.read_csv(f\"{cfg.path_results}run_results.csv\")\n",
    "#df_runs1 = df_runs[255:]  # filter which rows you want by eyeballing (usually these are part of a sweep)\n",
    "#df_config = df_runs1[['run_name','seed', 'dataset_name', 'gen_params_train.temperature', 'decode_method_eval']].drop_duplicates()\n",
    "df_config  = res_df.groupby(['dataset_name', 'gen_params_train.temperature', 'decode_method_eval'])['name']\\\n",
    "                     .apply(list).to_frame('run_names').reset_index()\n",
    "#run_lists = df_config['run_names'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>gen_params_train.temperature</th>\n",
       "      <th>decode_method_eval</th>\n",
       "      <th>run_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Sample</td>\n",
       "      <td>[proud-sweep-3, ruby-sweep-2, earthy-sweep-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Beam search</td>\n",
       "      <td>[zany-surf-809, absurd-sweep-8, vital-sweep-7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Diverse beam search (6 beam groups)</td>\n",
       "      <td>[devout-sweep-15, silvery-sweep-14, balmy-swee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Diverse beam search (48 beam groups)</td>\n",
       "      <td>[ancient-sweep-21, woven-sweep-20, happy-sweep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Sample</td>\n",
       "      <td>[magic-sweep-6, deep-sweep-5, fallen-sweep-4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Beam search</td>\n",
       "      <td>[faithful-dust-807, rich-sweep-11, flowing-swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Diverse beam search (6 beam groups)</td>\n",
       "      <td>[crisp-sweep-18, dashing-sweep-17, sandy-sweep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Diverse beam search (48 beam groups)</td>\n",
       "      <td>[grateful-sweep-24, restful-sweep-23, mild-swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FP</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Sample</td>\n",
       "      <td>[avid-sweep-27, unique-sweep-26, revived-sweep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FP</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Beam search</td>\n",
       "      <td>[polished-sweep-31, divine-sweep-32, glowing-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FP</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Diverse beam search (6 beam groups)</td>\n",
       "      <td>[devoted-sweep-37, comfy-sweep-36, gentle-swee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FP</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Diverse beam search (48 beam groups)</td>\n",
       "      <td>[rare-sweep-43, stoic-sweep-42, crisp-sweep-41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FP</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Sample</td>\n",
       "      <td>[cosmic-sweep-30, morning-sweep-29, apricot-sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FP</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Beam search</td>\n",
       "      <td>[rose-sweep-34, wild-sweep-33, lemon-sweep-32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FP</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Diverse beam search (6 beam groups)</td>\n",
       "      <td>[usual-sweep-40, polar-sweep-39, woven-sweep-38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FP</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Diverse beam search (48 beam groups)</td>\n",
       "      <td>[copper-yogurt-806, crimson-sweep-46, royal-sw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_name  gen_params_train.temperature  \\\n",
       "0            RT                          0.85   \n",
       "1            RT                          0.85   \n",
       "2            RT                          0.85   \n",
       "3            RT                          0.85   \n",
       "4            RT                          1.15   \n",
       "5            RT                          1.15   \n",
       "6            RT                          1.15   \n",
       "7            RT                          1.15   \n",
       "8            FP                          0.85   \n",
       "9            FP                          0.85   \n",
       "10           FP                          0.85   \n",
       "11           FP                          0.85   \n",
       "12           FP                          1.15   \n",
       "13           FP                          1.15   \n",
       "14           FP                          1.15   \n",
       "15           FP                          1.15   \n",
       "\n",
       "                      decode_method_eval  \\\n",
       "0                                 Sample   \n",
       "1                            Beam search   \n",
       "2    Diverse beam search (6 beam groups)   \n",
       "3   Diverse beam search (48 beam groups)   \n",
       "4                                 Sample   \n",
       "5                            Beam search   \n",
       "6    Diverse beam search (6 beam groups)   \n",
       "7   Diverse beam search (48 beam groups)   \n",
       "8                                 Sample   \n",
       "9                            Beam search   \n",
       "10   Diverse beam search (6 beam groups)   \n",
       "11  Diverse beam search (48 beam groups)   \n",
       "12                                Sample   \n",
       "13                           Beam search   \n",
       "14   Diverse beam search (6 beam groups)   \n",
       "15  Diverse beam search (48 beam groups)   \n",
       "\n",
       "                                            run_names  \n",
       "0       [proud-sweep-3, ruby-sweep-2, earthy-sweep-1]  \n",
       "1      [zany-surf-809, absurd-sweep-8, vital-sweep-7]  \n",
       "2   [devout-sweep-15, silvery-sweep-14, balmy-swee...  \n",
       "3   [ancient-sweep-21, woven-sweep-20, happy-sweep...  \n",
       "4       [magic-sweep-6, deep-sweep-5, fallen-sweep-4]  \n",
       "5   [faithful-dust-807, rich-sweep-11, flowing-swe...  \n",
       "6   [crisp-sweep-18, dashing-sweep-17, sandy-sweep...  \n",
       "7   [grateful-sweep-24, restful-sweep-23, mild-swe...  \n",
       "8   [avid-sweep-27, unique-sweep-26, revived-sweep...  \n",
       "9   [polished-sweep-31, divine-sweep-32, glowing-s...  \n",
       "10  [devoted-sweep-37, comfy-sweep-36, gentle-swee...  \n",
       "11    [rare-sweep-43, stoic-sweep-42, crisp-sweep-41]  \n",
       "12  [cosmic-sweep-30, morning-sweep-29, apricot-sw...  \n",
       "13     [rose-sweep-34, wild-sweep-33, lemon-sweep-32]  \n",
       "14   [usual-sweep-40, polar-sweep-39, woven-sweep-38]  \n",
       "15  [copper-yogurt-806, crimson-sweep-46, royal-sw...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', 0.85, 'Sample', ['proud-sweep-3', 'ruby-sweep-2', 'earthy-sweep-1']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['RT', 0.85, 'Beam search', ['zany-surf-809', 'absurd-sweep-8', 'vital-sweep-7']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['RT', 0.85, 'Diverse beam search (6 beam groups)', ['devout-sweep-15', 'silvery-sweep-14', 'balmy-sweep-13']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['RT', 0.85, 'Diverse beam search (48 beam groups)', ['ancient-sweep-21', 'woven-sweep-20', 'happy-sweep-19']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['RT', 1.15, 'Sample', ['magic-sweep-6', 'deep-sweep-5', 'fallen-sweep-4']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['RT', 1.15, 'Beam search', ['faithful-dust-807', 'rich-sweep-11', 'flowing-sweep-10']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['RT', 1.15, 'Diverse beam search (6 beam groups)', ['crisp-sweep-18', 'dashing-sweep-17', 'sandy-sweep-16']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['RT', 1.15, 'Diverse beam search (48 beam groups)', ['grateful-sweep-24', 'restful-sweep-23', 'mild-sweep-22']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['FP', 0.85, 'Sample', ['avid-sweep-27', 'unique-sweep-26', 'revived-sweep-25']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['FP', 0.85, 'Beam search', ['polished-sweep-31', 'divine-sweep-32', 'glowing-sweep-31']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['FP', 0.85, 'Diverse beam search (6 beam groups)', ['devoted-sweep-37', 'comfy-sweep-36', 'gentle-sweep-35']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['FP', 0.85, 'Diverse beam search (48 beam groups)', ['rare-sweep-43', 'stoic-sweep-42', 'crisp-sweep-41']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['FP', 1.15, 'Sample', ['cosmic-sweep-30', 'morning-sweep-29', 'apricot-sweep-28']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['FP', 1.15, 'Beam search', ['rose-sweep-34', 'wild-sweep-33', 'lemon-sweep-32']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['FP', 1.15, 'Diverse beam search (6 beam groups)', ['usual-sweep-40', 'polar-sweep-39', 'woven-sweep-38']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n",
      "['FP', 1.15, 'Diverse beam search (48 beam groups)', ['copper-yogurt-806', 'crimson-sweep-46', 'royal-sweep-45']]\n",
      "0.0\n",
      "\n",
      "########################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_and_process_run_results(cfg, run_name, split=\"test\"):\n",
    "    # Load results\n",
    "    df = get_training_dfs(f\"{cfg.path_checkpoints}{run_name}/\", postprocessed=False)[split]\n",
    "    if split != \"test\": \n",
    "        min_epoch,max_epoch = min(df['epoch']),max(df['epoch'])\n",
    "        df = df.query(\"epoch==@min_epoch or epoch==@max_epoch\")\n",
    "    # Agg to one row per orig example\n",
    "    df_any_adv_example = df.groupby(['idx', 'epoch'])['is_adv_example'].agg('sum').apply(lambda x: (x > 0)*1).reset_index()\n",
    "    # Setup baseline and trained conditions and pivot to get results\n",
    "    df_any_adv_example['condition'] = df_any_adv_example['epoch'].apply(lambda x: \"baseline\" if x==0 else \"trained\") \n",
    "    df_any_adv_example.drop(columns='epoch', inplace=True)\n",
    "    df_wide = df_any_adv_example.pivot(index='idx',  columns=['condition'])\n",
    "    df_wide.columns = [\"_\".join(a) for a in df_wide.columns.to_flat_index()]\n",
    "    df_wide.index = [f\"{run_name}_{c}\" for c in df_wide.index]\n",
    "    return df_wide\n",
    "\n",
    "def bootstrap_from_pd(df, b, A_col, B_col): \n",
    "    diff_overall =  df[A_col].sum() - df[B_col].sum()\n",
    "    diff_l = []\n",
    "    for i in range(b): \n",
    "        df_sample = df.sample(n=df.shape[0], replace=True)\n",
    "        diff_l.append(df_sample[A_col].sum() - df_sample[B_col].sum())\n",
    "   # print(diff_overall)\n",
    "   # print(diff_l)\n",
    "    condition_met = sum([ (diff_sample > (2 * diff_overall))*1  for diff_sample in diff_l])\n",
    "    p_val = condition_met/b      \n",
    "    return p_val\n",
    "\n",
    "\n",
    "\n",
    "# Bootstrap \n",
    "b = 10000\n",
    "split=\"test\"\n",
    "for index, row in df_config.iterrows(): \n",
    "    run_list = row['run_names']\n",
    "    print([o[1] for o in row.iteritems()])\n",
    "    df_l = []\n",
    "    for run_name in run_list:\n",
    "        df_l.append(load_and_process_run_results(cfg, run_name, split=split))\n",
    "    df_examples = pd.concat(df_l)\n",
    "    p_val = bootstrap_from_pd(df_examples, b=b, A_col=\"is_adv_example_trained\", B_col = \"is_adv_example_baseline\")\n",
    "    print(p_val)\n",
    "    print(\"\\n########################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(set_X, b): #returns p-value(x)\n",
    "    d_X = np.sum(list(zip(*set_X))[0]) - np.sum(list(zip(*set_X))[1]) # how much better does algorithm A do than B on x\n",
    "    d_X_1tob = [] \n",
    "    for i in range(0, b):\n",
    "        A1_b, B1_b = (0, 0)\n",
    "        # Draw a bootstrap sample x(i) of size n\n",
    "        for j in range(len(set_X)):\n",
    "            #Select a member of x at random and add it to x(i)\n",
    "            set_Xb = random.choice(set_X) \n",
    "            A1_b += set_Xb[0]\n",
    "            B1_b += set_Xb[1]\n",
    "        d_X_1tob.append(A1_b - B1_b)  #delta: how much better does algorithm A do than B on x(i)\n",
    "\n",
    "    #Count the samples on which algorithm A accidentally did better than B\n",
    "    s = 0  \n",
    "    for dx in d_X_1tob:\n",
    "        if dx > (2 * d_X):\n",
    "            s += 1    \n",
    "\n",
    "    #onesided empirical p-value \n",
    "    p_val = s/b      \n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "bstrap_input = [(1, 1),\n",
    " (1, 1),\n",
    " (0, 0),\n",
    " (0, 0)]\n",
    "print(bootstrap(bstrap_input, b=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bstrap_input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
